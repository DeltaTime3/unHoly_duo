
Minishell is divided into two parts:
	Parsing: where we treat the user input
	Execution: where you execute what have been parsed

Minishell is a command-line interpreter that mimics the bash and its basic funcionalities:
	Shell will work only in interactive mode, meaning no scripts - the executable takes no 
		arguments, it will start up and immediately enters a loop where it waits for user 
		input;
	Run simple commands with absolute, relative path (e.g. /bin/ls, ../bin/ls);
	Run simple commands without a path (e.g. ls, cat, grep, etc.);
	Navigation through commands with up/down arrows;
	Pipes;
	Redirections (<, >, >>);
	Here-doc (<<, delimeter that displays a new prompt, reads user input until reaching the 
	delimeter, redirects user input to command input - does not update history);
	Handle double quotes (""), and single quotes (''), which should escape special characters, 		
		beside $ for double quotes;
	Handle environment variables ($ followed by a sequence of characters, e.g. $USER or $VAR, that 	
	expand to their values);
	$?, expands to the exit status of the most recently executed foreground pipeline;
	Handle signals like in bash:
		ctrl + C, displays a new prompt line; 
		ctrl + D, exits minishell;
		ctrl + \, does nothing;
	Implement the following built-ins:
		echo (option -n only);
		exit;
		env (with no options or arguments);
		export (with no options);
		unset (with no options);
		cd;
		pwd;
	NOTE: Minishell does not support \, ;, &&, || or wildcards.

LEXING

Lexing (or tokenization) is the process of breaking down an input command line into a sequence of meaningful tokens. These tokens represent commands, arguments, operators, and other special characters. Essentially, the lexer identifies what's in the input string and categorizes it, without worrying about the command's validity or meaning.
Here's a more detailed breakdown:
	Input: The lexer takes the user's input command line as input. 
	Tokenization: It reads the input character by character, identifying different types of tokens. 
	Token Types: Common tokens include:
	Commands: The executable program (e.g., ls, echo). 
	Arguments: Data passed to the command (e.g., ls -l). 
	Operators: Piping (|), redirection (<, >, >>), and others. 
	Special Characters: Quotes, semicolons, and other symbols. 
	Output: The lexer produces a list or stream of these tokens. 
	Purpose: This token stream is then used by the parser to build an abstract syntax tree (AST) 
	that represents the structure of the command line. 
For example, the command ls -l | wc -w > output.txt would be lexed into tokens like: ls, -l, |, wc, -w, >, output.txt. 
The lexer is a crucial first step in processing user input in a Minishell implementation.

TWO THINGS TO TAKE CARE OF IN FRONT-END (which deals with user input and user interaction, like 
commands and signals)
	Commands (user input as a line/string);
	Signals (ctrl + C, etc.);

PARSING goes through two phases:
	1st, Lexical analysis/tokenization, which produces "lexems" or tokens;
	2nd, Syntax analysis (parsing the tokens);
	






























