LEXING CHECKLIST

X Understand the Input Format

	Familiarize yourself with the shell command syntax.
	Identify the types of tokens you need to recognize (e.g., commands, arguments, operators, 
	quotes).
	
X Define Token Types

	Create an enumeration or a set of constants for different token types (e.g., TOKEN_COMMAND, 
	TOKEN_ARGUMENT, TOKEN_PIPE, TOKEN_REDIRECT, etc.).
	
Implement the Lexer

	Write a function to read the input string character by character.
	Implement logic to handle different token types:
		Commands: Identify command names.
		Arguments: Capture arguments associated with commands.
		Operators: Handle pipes (|), redirection (>, <), and other shell operators.
		Quotes: Manage single (') and double (") quotes for strings.
		Handle whitespace appropriately (ignore or tokenize as needed).
X Tokenization

	Create a data structure (e.g., a linked list or array) to store the tokens.
	Ensure that each token is stored with its type and value.

X Error Handling

	Implement error handling for invalid tokens or malformed input.
	Provide meaningful error messages.

X Testing the Lexer

	Write unit tests for the lexer to ensure it correctly identifies and tokenizes various command 	
	inputs.
	Test edge cases (e.g., empty input, unbalanced quotes).

PARSING CHECKLIST

X Understand the Grammar

	Define the grammar rules for your shell commands (e.g., command structure, argument handling, 
	operator precedence).
	
- Define the Abstract Syntax Tree (AST) Structure

	Create data structures to represent the AST nodes (e.g., command nodes, argument nodes, 
	operator nodes).

Implement the Parser

	Write a function to parse the list of tokens generated by the lexer.
	Implement recursive descent parsing or another parsing technique based on your grammar.
	Build the AST as you parse the tokens.

Handle Command Execution

	Ensure that the parser can identify when to execute commands and how to handle built-in 	
	commands versus external commands.

Error Handling

	Implement error handling for syntax errors in the command input.
	Provide meaningful error messages for parsing issues.
	
Testing the Parser

	Write unit tests for the parser to ensure it correctly builds the AST from various token 
	inputs.
	Test edge cases (e.g., incomplete commands, invalid syntax).

Final Steps

Integration

	Integrate the lexer and parser into your minishell project.
	Ensure that the lexer feeds tokens into the parser correctly.

Documentation

	Document your code and the design decisions you made during the lexing and parsing process.

Code Review

	If possible, have a peer review your code for feedback and suggestions.

Refinement

	Refine your lexer and parser based on testing and feedback.

Prepare for Next Steps

	Once lexing and parsing are complete, prepare to move on to the next parts of your project 
	(e.g., execution, environment handling).
	
	
	
